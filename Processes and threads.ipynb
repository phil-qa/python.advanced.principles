{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# very basic threads\n",
    "The following shows threading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Synchronisation objects\n",
    "POSIX - Portable operating system\n",
    "\n",
    " If another transaction B currently has an exclusive lock on any object matching those conditions, A must wait until B releases its lock before it is allowed to make its query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at semaphore, the analogy is that it controls the number of threads access\n",
    "\n",
    "Semaphores are nothing more complicated than a shared counter. \n",
    "When you call down() the counter is decreased - and it will block if it cannot. If you call up() the count is incremented. (And anything blocking will be released). \n",
    "However, until that 'block' occurs, the threads can - and will - execute in an undefined order, that you should assume is random. (It isn't entirely, but relying on any particular sequence will create race conditions).\n",
    "It's not complicated, but one of the things that can trip you up is buffering - print statements in threads may get buffered, so appear to arrive in strange order.\n",
    "\n",
    "## mutex\n",
    "mutex mutual exclusion  concurrency control, which is instituted for the purpose of preventing race conditions. It is the requirement that one thread of execution never enters a critical section while a concurrent thread of execution is already accessing said critical section. Python locks in p3 use lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From thread th 1\n",
      "From thread th 2\n",
      "from main\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def test_function(*args):\n",
    "    print(\"From thread\", ''.join(args))\n",
    "    time.sleep(5)\n",
    "\n",
    "th1 = Thread(target= test_function, args='th 1')\n",
    "th2 = Thread(target= test_function, args='th 2')\n",
    "\n",
    "th1.start()\n",
    "th2.start()\n",
    "\n",
    "print(\"from main\")\n",
    "\n",
    "th1.join()\n",
    "th2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Global Interpreter Lock\n",
    "Learn what Global Interpreter Lock is, how it works, and why you should use it.\n",
    "A global interpreter lock (GIL) is a mechanism to apply a global lock on an interpreter. It is used in computer-language interpreters to synchronize and manage the execution of threads so that only one native thread (scheduled by the operating system) can execute at a time.\n",
    "In a scenario where you have multiple threads, what can happen is that both the thread might try to acquire the memory at the same time, and as a result of which they would overwrite the data in the memory. Hence, arises a need to have a mechanism that could help prevent this phenomenon.\n",
    "Some popular interpreters that have GIL are CPython and Ruby MRI. As most of you would know that Python is an interpreted language, it has various distributions like CPython, Jython, IronPython. Out of these, GIL is supported only in CPython, and it is also the most widely used implementation of Python. CPython has been developed in both C and Python language primarily to support and work with applications that have a lot of C language underneath the hood.\n",
    "Even if your processor has multiple cores, a global interpreter will allow only one thread to be executed at a time. This is because, when a thread starts running, it acquires the global interpreter lock. When it waits for any I/O operation ( reading/writing data from/to disk ) or a CPU bound operation ( vector/matrix multiplication ), it releases the lock so that other threads of that process can run. Hence, it prevents you from running the other threads at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "  \n",
    "  \n",
    "class Process(multiprocessing.Process):\n",
    "    def __init__(self, id):\n",
    "        super(Process, self).__init__()\n",
    "        self.id = id\n",
    "                 \n",
    "    def run(self):\n",
    "        time.sleep(1)\n",
    "        print(\"I'm the process with id: {}\".format(self.id))\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    p = Process(0)\n",
    "    p.start()\n",
    "    p.join()\n",
    "    p = Process(1)\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Process(0)\n",
    "p.start()\n",
    "p.join()\n",
    "p = Process(1)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
